---
title: "Benthic: Making Diagrams Make Sense Through Screen Readers"
author: Daniel Hajas
AI_assistance: AI-generated
hero: 
hero_alt: 
hero_caption: 
tags: [representational-productivity-tools]
related_publications: [benthic-assets-2025]
related_external_posts:
  - title:
    url:
---

Charts and diagrams aren’t just pictures—they’re structures. Boxes contain other boxes; arrows connect ideas; groups form wholes. Sighted readers pick up these relationships at a glance. Screen reader users, meanwhile, are too often given a flat wall of alt text.

<!--more-->

In our latest and greatest work in collaboration with the MIT Visualisation Group, **Benthic**, we align what you *feel* through a screen reader with what’s *there* in the graphic. Instead of forcing every diagram into a single tree or a simple network, Benthic models diagrams as **hypergraphs**. That lets us capture both **containment** (part–whole, nesting) and **adjacency** (connections) at the same time—then turn that structure into a **fluid, reversible navigation** you can skim, zoom into, and back out of without losing your place. We call this alignment **perceptual congruence**: the navigational structure matches the graphic’s inherent structure.

We evaluated Benthic with **15 blind participants** across common diagram types. People used it to form clear mental models faster, switch strategies mid-stream (overview → detail → compare), and stay oriented as they explored.

Our takeaway: accessibility shouldn’t flatten structure. When screen reader navigation mirrors a diagram’s true relationships, exploration becomes natural, confident, and efficient—bringing charts and diagrams within reach as rich, learnable spaces rather than long paragraphs to endure.