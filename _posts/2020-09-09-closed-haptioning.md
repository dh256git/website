---
title: A new channel of access to educational multimedia
author: Daniel Hajas
AI_assistance: AI-generated
hero: 
hero_alt: 
hero_caption: 
tags: [crossmodal-ux-collaboration, flow-centred-design-haptic-learning]
related_publications: [closed-haptioning-eurohaptics-2020, mid-air-haptic-pointer-toh-2020]
related_external_posts:
  - title:
    url:
---

Captions and audio description are powerful tools for making films and educational videos more inclusive. But sometimes, words alone can’t capture what’s happening on screen. Imagine trying to describe the swirling motion of an animation or the sharp outline of a geometric shape—much of the richness gets lost.

<!--more-->

That’s where our idea of **Closed Haptioning** comes in. Instead of only adding text or spoken narration, we add a channel of *touch*—delivered through mid-air haptic technology. Using ultrasound, we can project tactile sensations directly onto a viewer’s hands, without any wearable devices.

In our demonstration, we synchronised a short video with tactile patterns that traced shapes like circles, triangles, and squares in mid-air. By using a new technique we call **Dynamic Tactile Pointers**, recognition accuracy improved by about 30% compared to older methods. This means complex visuals can be “felt” more clearly.

For people who are blind or partially sighted, closed haptioning could offer an additional layer of access. But we also see it as a way to make films, education, and even entertainment more immersive for *everyone*. Just as captions once transformed accessibility, we believe haptioning can open new dimensions—making visual stories truly multisensory.