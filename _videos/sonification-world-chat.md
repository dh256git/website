---
title: "Seminar Presentation: Sonification World Chat (SWC) WOrkshop Series"
author: Daniel Hajas
date: 2021-09-06
youtube_id: 4v5lBiLqX4U
youtube_title: "Talking about the potential of Mid-Air Haptics in science communication"
tags: [flow-centred-design-haptic-learning, constructive-play-simulations]
related_publications: [mid-air-haptic-pointer-toh-2020, aquarium-chi-ea-2020, closed-haptioning-eurohaptics-2020, cosmology-multisensory-jcom-2020, i-can-feel-it-moving-frontiers-2020]
summary: In this video, Daniel Hajas gives an overview of his PhD research portfolio at the fourth workshop of the Sonification WOrld Chat workshop series. At the time of this presentation, Daniel is researching tangible user interfaces and actuators. His research is targeting the use of tactile experiences for purposes of provoking personal responses, which are known to be relevant in science communication, such as interest or enjoyment.
---

**Introduction**
Thank you for your patience. I’ll try to keep this fairly short and introductory, mainly because while most of us have speakers to share sounds, we don’t quite have haptic displays at our disposal yet.

Since this is my first time joining the meeting, I’ll explain a little about who I am and what I work on, and then leave a few minutes for questions so we can discuss how haptification might be used for science communication.

**Overview**
I’m from the University of Sussex, where I did my undergraduate degree in physics. Later, I became more interested in science communication, particularly how we can use touch to communicate science. That led me to start a PhD.

The graphic I often use shows two hands with an illustration of an atom hovering above them, suspended in mid-air. It’s an iconic representation of what I’m aiming to achieve: merging three fields—haptics (the science of touch), science communication, and natural mid-air interaction without wearables or restrictive technology.

**About me**
I’m originally from Hungary but have lived abroad for many years, including the past seven years in England, where I completed my degrees in theoretical physics. As I mentioned, I became more interested in novel ways of communicating science.

I’m also blind—I lost my sight around ten years ago. So I know what it was like to study science visually and to stargaze through a telescope, and I also know the challenges and the loss of certain experiences when vision is no longer available.

**About ultrasonic mid-air haptics**
Ultrasonic mid-air haptics can be thought of as “inaudible sonification.” The technology I work with uses ultrasound to generate tactile sensations in mid-air. This approach was pioneered in Japan in 2008, then further developed at the University of Bristol, where a company was founded in 2013 to commercialize it.

The system uses an array of ultrasound speakers, similar to parking sensors in cars. They emit 40 kHz ultrasound, but by modulating and focusing the waves into a single point, we can create enough pressure to indent the skin and generate a tactile sensation. Since human skin perceives vibrations up to around 500 Hz, modulation is essential to make the sensations feel natural.

**Applications in science communication**
In one of my studies, we asked science communicators to try mid-air haptics programmed with concepts such as a cell nucleus, a particle collision, and quantum phenomena. We asked them why they felt this technology was useful compared to others like 3D printing or VR.

Their feedback was that the technology is tactile, dynamic, and programmable. Unlike a physical spring, which loses its motion when touched, haptics can continuously generate dynamic sensations without disturbance. It is also invisible and does not require gloves or equipment, making it easy to combine with visuals, VR, or sonification.

**A multisensory dark matter experience**
In collaboration with Imperial College London, we created a multisensory exhibition about dark matter. It was metaphorical, combining scent, haptics, sound, narration, and visuals to create a narrative journey from Earth to the center of our galaxy. This was exhibited several times at the London Science Museum.

We also worked on a project with the Aquarium of the Pacific in Los Angeles, where the goal was to make film experiences about oceanography and renewable energy more immersive and accessible for people with sensory impairments. Here, we explored whether sensations should directly map to visuals (e.g., feeling a fish swim across your palm when one appeared on screen) or be metaphorical (e.g., feeling strong winds when the narration mentioned them). Both approaches had potential, and the project received very positive feedback.

**Closed haptioning (Eurohaptics 2020)**
Another project, which I plan to present at Eurohaptics, focused on rendering shapes—such as circles, triangles, and squares—through haptics. We studied the best methods for creating perceivable shapes and achieved a 30% improvement in recognition accuracy.

We also experimented with pairing haptic shapes with closed captions. For example, if a video showed an animation of a circle with narration, closed captions could describe the shape while the viewer felt it simultaneously. This provided a form of accessible “haptioning” that paralleled but extended traditional captioning.

**Conclusion**
In closing, I believe touch has enormous potential in science communication, both in formal and informal learning environments. From what I’ve heard in today’s presentations, combining sound and touch could be powerful in many different scenarios.

Thank you, and I’d be happy to take questions now or later.