---
permalink: /assets/transcripts/accessible-multimedia-through-closed-haptions.html
title: "Accessible multimedia through closed haptions"
date: 2025-08-21
categories: transcript
audio_length: "08:55:00"
recorded: "09:08 AM"
participants:
  - Speaker 1 (AI host 1)
  - Speaker 2 (AI host 2)
source_url: /media/podcasts/accessible-multimedia-through-closed-haptions/
---

**Speaker 1**
Welcome, deep divers, here on the Deep Dive. Our mission is, well, to cut through all that information noise, sift through the latest stuff, and hand you those key nuggets so you can get genuinely well-informed fast. We're always after those real aha moments. Today we're diving into something pretty innovative that could really shift how we access information, maybe even how we perceive the world. We're going, like, way beyond traditional accessibility here.

**Speaker 2**
Exactly. You know, we rely a lot on closed captions, audio descriptions. They're essential, absolutely right. But they do have limits. They can't always get all the important info across, especially if the visuals are super complex. Think about an animated science concept in a video.

**Speaker 1**
Yeah, like nonstop animation.

**Speaker 2**
Exactly. There's often just no room for audio description to explain what's happening visually without, you know, talking over the main point.

**Speaker 1**
So, right. If you can't see it properly, or maybe you can't hear that extra description, how do you get that vital info? And that's where this paper we're looking at comes in, suggesting a whole new sense almost.

**Speaker 2**
Yeah.

**Speaker 1**
We are taking a deep dive into this fascinating research paper. It's called *Closed Haptioning: A demonstration of using midair haptics for improving accessibility of audiovisual content beyond closed captions and audio description.* It's by Daniel Hodges, Dariel Pitera, and Mariana Obrist. So our mission today: figure out what midair haptics actually are, how this closed haptioning thing works, and why it might be a genuine game-changer for accessibility. I'm going to take you from just curious to really understanding it. Okay, let's unpack this.

**Speaker 2**
So, like we were saying, captions and audio descriptions are crucial, but they hit a wall sometimes, especially with really dynamic visuals or stuff that's just packed with detail. You know, that biology animation example—trying to describe everything happening, it just wouldn't work with the main audio track.

**Speaker 1**
That's the core problem, isn't it?

**Speaker 2**
Yeah.

**Speaker 1**
How do you get that richness across when sight or sound are already busy, or maybe not freely available? And this research points to adding touch.

**Speaker 2**
Exactly. Touch, but in a really novel way. It uses ultrasonic midair haptic technology. Okay, so imagine sound waves way above human hearing, focused really precisely. They create these tiny pockets of air pressure you can actually feel on your skin.

**Speaker 1**
Wow. Like a little puff of air, but shaped, sort of.

**Speaker 2**
Yeah, it's like a tactile sensation, just floating there. No need to touch a screen or anything. And that's the tech behind what they call closed haptioning.

**Speaker 1**
That is incredible. It really does sound futuristic. But you're saying it's... well, it's actually being developed now. So closed haptioning—are they like captions you feel instead of read?

**Speaker 2**
That's a great way to put it. Yes. Closed haptioning lets you feel information that's usually visual or maybe auditory. And crucially, they're synchronized perfectly with the audio and video, so you get this complete multisensory experience. It's about adding tactile cues to make complex stuff clearer.

**Speaker 1**
Got it. So it complements, doesn’t just replace.

**Speaker 2**
Precisely. Especially for those complex visual stories. And the paper gets into the really clever ways they actually render these shapes you feel in the air. There's an older way, spatiotemporal modulation, or STM.

**Speaker 1**
STM?

**Speaker 2**
Yeah. Think of it like drawing a shape super, super fast with a point of feeling. So fast your skin just perceives the whole outline at once. Like persistence of vision, but for touch.

**Speaker 1**
Okay, so that’s one. You mentioned a breakthrough, right?

**Speaker 2**
The paper talks about the dynamic tactile pointer, or DTP. This is different. Imagine just one focal point of feeling, slowly tracing the shape's outline in the air.

**Speaker 1**
Ah, so you can follow it along, like tracing with your finger, but without touching anything.

**Speaker 2**
Exactly. And then they found something even more effective: the multistroke dynamic tactile pointer, MSDTP.

**Speaker 1**
Okay. Multistroke.

**Speaker 2**
Yeah. This isn't just one slow trace. It breaks the shape down into distinct parts, distinct haptic strokes. And crucially, there are short pauses between these strokes, these movements.

**Speaker 1**
Pauses. Okay, so STM is fast, DTP is slow and smooth, MSDTP is slow with pauses. Why is that distinction such a big deal? What did the research find with MSDTP?

**Speaker 2**
Well, this is where it gets really interesting. They found that using MSDTP makes it dramatically easier for people to identify the shapes compared to STM or even the single-stroke DTP.

**Speaker 1**
Dramatically easier? Like how much?

**Speaker 2**
Okay, get this. A square, right? Rendered using MSDTP with a tiny pause—just 300 milliseconds—on the corners. People were about 30% more likely to correctly identify it as a square compared to one rendered without those corner pauses.

**Speaker 1**
30% just from adding a little stop at the corners? That's huge.

**Speaker 2**
It is huge. It really tells us something fundamental about how we process tactile information.

**Speaker 1**
What does it suggest? It feels like more than just, you know, a technical detail.

**Speaker 2**
Oh, absolutely. That 30% isn't just a number. It strongly suggests our tactile system benefits hugely from these little punctuation marks.

**Speaker 1**
The pauses, like breaking it down.

**Speaker 2**
Exactly. It helps segment the information, makes it clearer. It implies our brains might actually be better at processing tactile input in these sort of discrete chunks, rather than just one continuous flow. It's a really key insight for designing these kinds of experiences.

**Speaker 1**
That makes a lot of sense. So the practical takeaway for designing any kind of midair haptic interface—like icons or controls—is that MSDTP with those smart pauses is probably the way to go for clarity.

**Speaker 2**
Definitely seems that way. Based on this research, it's the preferred choice for making things clearly identifiable.

**Speaker 1**
And they actually tested this out, right? The paper mentions a demonstration called Squiz. Like a shape quiz.

**Speaker 2**
Yeah, exactly. Squiz. Picture this: you're presented with five different geometric shapes rendered haptically in midair—a line, circle, triangle, square, rectangle. But in a random order.

**Speaker 1**
Okay. So you just feel them appear.

**Speaker 2**
You feel them appear one after the other. And the task for the attendees was to figure out the sequence, the order they were presented in. And they tried this using the three different rendering methods—STM, DTP, MSDTP—which basically represented different difficulty levels.

**Speaker 1**
Ah. So they could directly compare how easy it was to tell the shapes apart with each method.

**Speaker 2**
Precisely. A real hands-on test.

**Speaker 1**
And this is where the closed haptioning part really clicked, right? They showed visualizations too.

**Speaker 2**
Yes, that's key. While people were feeling the shapes via the haptic array, there were also visuals shown. And these visuals perfectly matched the haptic sensations both in what shape was shown and when it was shown.

**Speaker 1**
So the feeling and the seeing were perfectly in sync. True closed haptioning.

**Speaker 2**
Exactly. A complete synchronized sensory feed. And it's not just theoretical or a one-off demo. They mention similar work using closed haptioning has already been published. I think there was an example enhancing a short documentary about oceanography.

**Speaker 1**
Oh, interesting. So it's already being applied.

**Speaker 2**
Yeah. To improve both accessibility and the immersive feeling of the content. It shows it has real-world uses right now.

**Speaker 1**
Okay. So it clearly solves a specific accessibility problem very effectively. But thinking bigger picture now, what really stands out to you about the broader impact this could have?

**Speaker 2**
Well, firstly, just thinking about interface design. These findings are super important for anyone creating tactile icons. Imagine interacting with your phone or maybe a public kiosk just by feeling options in the air.

**Speaker 1**
Yeah. No more smudged screens.

**Speaker 2**
Right. But maybe even more profound—think about education, particularly geometry for visually impaired students.

**Speaker 1**
Oh, wow. Yeah.

**Speaker 2**
Trying to learn about shapes and angles just from words is incredibly difficult. This tech could let students actually feel a triangle, feel the difference between a square and a rectangle directly, without needing...

**Speaker 1**
Physical models for everything.

**Speaker 2**
Exactly. Which could be huge, especially in areas with fewer resources, more remote regions. It could really level the playing field.

**Speaker 1**
So it's not just patching a hole in existing accessibility. It's potentially opening up totally new ways to learn and interact with information. Kind of blurring digital and physical through touch.

**Speaker 2**
Right. So to wrap up, we've journeyed through closed haptioning and midair haptics, seeing how they push way beyond current accessibility tools. They offer this genuinely tactile channel for information—from that frankly amazing 30% boost in recognizing shapes just by adding pauses...

**Speaker 1**
Yeah. The MSDTP finds its potential in new ways of teaching really complex subjects like geometry. It really does feel groundbreaking.

**Speaker 2**
And it leaves us—and you—with a really interesting question to ponder, doesn't it?

**Speaker 1**
Go on.

**Speaker 2**
If we can now feel shapes, feel animations right there in midair, what other kinds of information—things currently locked into sight or sound—could we unlock or even enhance through this sense of touch? Hmm, that's a big question. Imagine feeling data visualizations, complex data sets, or maybe even using it in gaming for more immersion. The possibilities seem vast. This has been a truly fascinating deep dive into a future where knowledge isn't just seen or heard, but actually felt. Until next time, keep exploring.